{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "# from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import catboost as cb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_parquet('data/all_data.parquet')\n",
    "# print('Columns:', all_data.columns)\n",
    "all_data.info()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[[\n",
    "     'shop_id',\n",
    "     'item_id',\n",
    "     'date_block_num',\n",
    "     'target',\n",
    "     'target_shop',\n",
    "     'target_item',\n",
    "     'target_mean',\n",
    "     'target_shop_mean',\n",
    "     'target_item_mean',\n",
    "#      'target_item_shop_mean',\n",
    "     'target_lag_1',\n",
    "     'target_item_lag_1',\n",
    "     'target_item_mean_lag_1',\n",
    "     #'target_item_shop_mean_lag_1',\n",
    "     'target_mean_lag_1',\n",
    "     'target_shop_lag_1',\n",
    "     'target_shop_mean_lag_1',\n",
    "     'target_lag_2',\n",
    "     'target_item_lag_2',\n",
    "     'target_item_mean_lag_2',\n",
    "     #'target_item_shop_mean_lag_2',\n",
    "     'target_mean_lag_2',\n",
    "     'target_shop_lag_2',\n",
    "     'target_shop_mean_lag_2',\n",
    "     'target_lag_3',\n",
    "     'target_item_lag_3',\n",
    "     'target_item_mean_lag_3',\n",
    "     #'target_item_shop_mean_lag_3',\n",
    "     'target_mean_lag_3',\n",
    "     'target_shop_lag_3',\n",
    "     'target_shop_mean_lag_3',\n",
    "     'target_lag_4',\n",
    "     'target_item_lag_4',\n",
    "     'target_item_mean_lag_4',\n",
    "     #'target_item_shop_mean_lag_4',\n",
    "     'target_mean_lag_4',\n",
    "     'target_shop_lag_4',\n",
    "     'target_shop_mean_lag_4',\n",
    "     'target_lag_5',\n",
    "     'target_item_lag_5',\n",
    "     'target_item_mean_lag_5',\n",
    "     #'target_item_shop_mean_lag_5',\n",
    "     'target_mean_lag_5',\n",
    "     'target_shop_lag_5',\n",
    "     'target_shop_mean_lag_5',\n",
    "     'target_lag_12',\n",
    "     'target_item_lag_12',\n",
    "     'target_item_mean_lag_12',\n",
    "#      'target_item_shop_mean_lag_12',\n",
    "     'target_mean_lag_12',\n",
    "     'target_shop_lag_12',\n",
    "     'target_shop_mean_lag_12',\n",
    "     'item_category_id',\n",
    "     'city_code',\n",
    "     'type_code',\n",
    "     'subtype_code',\n",
    "     'month_num',\n",
    "     'item_first_sale',\n",
    "     'item_shop_first_sale',\n",
    "     'days'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all lagged features\n",
    "\n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = ['target_shop_mean', 'target_shop', \n",
    "                'target_item', 'target', 'target_item_mean', 'target_mean', 'date_block_num'] #, 'target_item_shop_mean']\n",
    "\n",
    "# Categorical features\n",
    "cat_features = ['shop_id', 'item_id', 'item_category_id', 'city_code', \n",
    "                'type_code', 'subtype_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()-1\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = dates[dates <  last_block]\n",
    "dates_test  = dates[dates == last_block]\n",
    "\n",
    "X_train =  all_data.loc[dates <  last_block].drop(to_drop_cols, axis=1)\n",
    "X_test =   all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n",
    "X_target = all_data.loc[dates == dates.max()].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_test =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement a basic stacking scheme. We have a time component here, so we will use ***scheme f)*** from the reading material. Recall, that we always use first level models to build two datasets: test meta-features and 2-nd level train-metafetures. Let's see how we get test meta-features first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firts, we will run *linear regression* on numeric columns and get predictions for the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train.values, y_train)\n",
    "pred_lr = model_lr.predict(X_test.values)\n",
    "\n",
    "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))\n",
    "print('Test RMSE linreg is %f' % np.sqrt(mean_squared_error(y_test, pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lor = LogisticRegression(random_state=17, n_jobs=4, solver='saga', verbose=1)\n",
    "model_lor.fit(X_train.values, y_train)\n",
    "pred_lor = model_lor.predict(X_test.values)\n",
    "\n",
    "print('Test R-squared for LogReg is %f' % r2_score(y_test, pred_lor))\n",
    "print('Test RMSE LogReg is %f' % np.sqrt(mean_squared_error(y_test, pred_lor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the we run *LightGBM*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# LightGGM\n",
    "model_lgb = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    "    objective='mse',\n",
    "    random_state=17\n",
    ")\n",
    "model_lgb.fit(X_train, y_train, \n",
    "              eval_set=(X_test, y_test), \n",
    "              early_stopping_rounds=100,\n",
    "              verbose=100)\n",
    "pred_lgb = model_lgb.predict(X_test)\n",
    "\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))\n",
    "print('Test RMSE LightGBM is %f' % np.sqrt(mean_squared_error(y_test, pred_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Catboost\n",
    "\n",
    "model_cbr = cb.CatBoostRegressor(loss_function='RMSE',\n",
    "                                 cat_features=cat_features,\n",
    "                                 iterations=1000,\n",
    "                                task_type='CPU')\n",
    "model_cbr.fit(X_train, y_train, \n",
    "              eval_set=(X_test, y_test), \n",
    "              verbose=20, \n",
    "              early_stopping_rounds=50,\n",
    "              plot=True)\n",
    "pred_cb = model_cbr.predict(X_test)\n",
    "\n",
    "print('Test R-squared for CatBoost is %f' % r2_score(y_test, pred_cb))\n",
    "print('Test RMSE CatBoost is %f' % np.sqrt(mean_squared_error(y_test, pred_cb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importance = model_cbr.get_feature_importance(prettified=True)\n",
    "f_importance.sort_values(by='Importances', ascending=True).set_index('Feature Id').plot(\n",
    "    kind='barh', figsize=(10,10), legend=False, grid=True, title=\"Feature importances\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# model_svr = SVR()\n",
    "# model_svr.fit(X_train.values, y_train)\n",
    "# pred_svr = model_svr.predict(X_test.values, verbose=True)\n",
    "\n",
    "# print('Test R-squared for SVR is %f' % r2_score(y_test, pred_svr))\n",
    "# print('Test RMSE SVR is %f' % np.sqrt(mean_squared_error(y_test, pred_svr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# XGBM\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=500, n_jobs=4, random_state=17)\n",
    "model_xgb.fit(X_train, y_train, \n",
    "              eval_set=[(X_test, y_test)], \n",
    "              eval_metric=\"rmse\", \n",
    "              verbose=10, \n",
    "              early_stopping_rounds = 50)\n",
    "pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('Test R-squared for XGBoost is %f' % r2_score(y_test, pred_xgb))\n",
    "print('Test RMSE XGBoost is %f' % np.sqrt(mean_squared_error(y_test, pred_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot XGBoost features importance\n",
    "from xgboost import plot_importance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "plot_importance(booster=model_xgb, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenate test predictions to get test meta-features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions for test data\n",
    "train_lr  = model_lr.predict(X_train)\n",
    "train_lgb = model_lgb.predict(X_train)\n",
    "train_cbr = model_cbr.predict(X_train)\n",
    "train_xgb = model_xgb.predict(X_train)\n",
    "\n",
    "X_train_level2 = np.c_[train_lr, train_lgb, train_cbr, train_xgb] \n",
    "# X_test_level2.tofile('X_test_level2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_level2, X_train_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions for test data\n",
    "test_lr  = model_lr.predict(X_test)\n",
    "test_lgb = model_lgb.predict(X_test)\n",
    "test_cbr = model_cbr.predict(X_test)\n",
    "test_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "X_test_level2 = np.c_[test_lr, test_lgb, test_cbr, test_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_level2, X_test_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make prediction for target data\n",
    "target_lr  = model_lr.predict(X_target)\n",
    "target_lgb = model_lgb.predict(X_target)\n",
    "target_cbr  = model_cbr.predict(X_target)\n",
    "target_xgb = model_xgb.predict(X_target)\n",
    "\n",
    "X_target_level2 = np.c_[target_lr, target_lgb, target_cbr, target_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target_level2, X_target_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_lr = LinearRegression()\n",
    "l2_model_lr.fit(X_train_level2, y_train)\n",
    "test_l2_lr = l2_model_lr.predict(X_test_level2)\n",
    "\n",
    "print(f'Test RMSE for LinearRegression L2 is {np.sqrt(mean_squared_error(y_test, test_l2_lr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_lor = LinearRegression()\n",
    "l2_model_lor.fit(X_train_level2, y_train)\n",
    "test_l2_lor = l2_model_lor.predict(X_test_level2)\n",
    "\n",
    "print(f'Test RMSE for LogisticRegression L2 is {np.sqrt(mean_squared_error(y_test, test_l2_lor))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model_cb = cb.CatBoostRegressor(loss_function='RMSE',\n",
    "                               task_type='CPU')\n",
    "l2_model_cb.fit(X_train_level2, y=y_train,\n",
    "             eval_set=(X_test_level2, y_test),\n",
    "             early_stopping_rounds=50,\n",
    "             verbose=20,\n",
    "             plot=True)\n",
    "test_l2_cbr = l2_model_cb.predict(X_test_level2)\n",
    "\n",
    "print(f'Test RMSE for CatBoost L2 is {np.sqrt(mean_squared_error(y_test, test_l2_cbr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
